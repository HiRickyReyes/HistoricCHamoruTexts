{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /Users/ricky/digital_texts/corpus/files/0_tei_files/finalized_tei/marianas_mosiac.xml\n",
      "Processing: /Users/ricky/digital_texts/corpus/files/0_tei_files/finalized_tei/guam_two_invasions_and_three_military_occupations.xml\n",
      "Processing: /Users/ricky/digital_texts/corpus/files/0_tei_files/finalized_tei/legacy_of_a_political_union.xml\n",
      "Processing: /Users/ricky/digital_texts/corpus/files/0_tei_files/finalized_tei/eng_chamoru_legends.xml\n",
      "Processing: /Users/ricky/digital_texts/corpus/files/0_tei_files/finalized_tei/destinys_landfall.xml\n",
      "Processing: /Users/ricky/digital_texts/corpus/files/0_tei_files/finalized_tei/history_of_the_chamorro_people.xml\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# loading spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# defining a function to extract only nouns and adjectives\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    processed_tokens = [token.lemma_ for token in doc if token.pos_ in ['NOUN', 'ADJ']]\n",
    "    return \" \".join(processed_tokens)  # returning processed texts\n",
    "\n",
    "# apply function ^ to filepath\n",
    "filepath = \"/Users/ricky/digital_texts/corpus/files/0_tei_files/finalized_tei\"\n",
    "metadata_list = []\n",
    "text_list = []\n",
    "raw_text_list = []\n",
    "\n",
    "for entry in os.scandir(filepath):\n",
    "    if entry.name.startswith(\".\"):  # identified an issue with a hidden file so this prevents issues w/ utf8 encoding stopping the process\n",
    "        continue\n",
    "    print(f\"Processing: {entry.path}\")  # for tracking during the process\n",
    "    try:\n",
    "        with open(entry.path, encoding=\"utf-8\") as file:\n",
    "            xml_content = file.read()\n",
    "        # parsing file w/ beautiful soup to extract metadata\n",
    "        soup = bs(xml_content, \"xml\")\n",
    "        author = soup.author.text.strip() if soup.author else \"Unknown\"\n",
    "        title = soup.title.text.strip() if soup.title else \"Untitled\"\n",
    "        pub_date = soup.date.text.strip() if soup.date else \"Unknown\"\n",
    "        in_out = soup.affiliation.text.strip() if soup.affiliation else \"Unknown\"\n",
    "        # storing the metadata\n",
    "        metadata = {\n",
    "            \"author\": author,\n",
    "            \"title\": title,\n",
    "            \"pub_date\": pub_date,\n",
    "            \"insider/outsider\": in_out,\n",
    "        }\n",
    "        metadata_list.append(metadata)\n",
    "\n",
    "        # preprocessing and extracting the text\n",
    "        text = soup.body.text if soup.body else \"\"\n",
    "        raw_text_list.append(text)\n",
    "        processed_text = preprocess_text(text)  \n",
    "        text_list.append(processed_text)\n",
    "    except UnicodeDecodeError:  # again, found an error that was preventing the processing of texts with a hidden file - this is to keep the process moving\n",
    "        print(f\"UnicodeDecodeError in file: {entry.path}\")\n",
    "        continue  \n",
    "print(\"Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for 'A Marianas Mosaic: Signs and Shifts in Contemporary Island Life':\n",
      "generation    0.259778\n",
      "other         0.216253\n",
      "people        0.212301\n",
      "culture       0.203745\n",
      "island        0.180117\n",
      "Name: A Marianas Mosaic: Signs and Shifts in Contemporary Island Life, dtype: float64 \n",
      "\n",
      "Top words for 'GUAM: TWO INVASIONS AND THREE MILITARY OCCUPATIONS':\n",
      "japanese     0.430121\n",
      "naval        0.224926\n",
      "gun          0.202889\n",
      "island       0.197352\n",
      "guamanian    0.186958\n",
      "Name: GUAM: TWO INVASIONS AND THREE MILITARY OCCUPATIONS, dtype: float64 \n",
      "\n",
      "Top words for 'Legacy of a Political Union: A Founding Father's Memoir':\n",
      "negotiation    0.353061\n",
      "people         0.331279\n",
      "political      0.221373\n",
      "member         0.191123\n",
      "citizen        0.158975\n",
      "Name: Legacy of a Political Union: A Founding Father's Memoir, dtype: float64 \n",
      "\n",
      "Top words for 'Chamoru Legends: A Gathering of Stories':\n",
      "tree       0.292939\n",
      "brother    0.204505\n",
      "child      0.190687\n",
      "man        0.165218\n",
      "time       0.155640\n",
      "Name: Chamoru Legends: A Gathering of Stories, dtype: float64 \n",
      "\n",
      "Top words for 'Destiny’s Landfall: A History of Guam':\n",
      "ship       0.427217\n",
      "island     0.330497\n",
      "spanish    0.218128\n",
      "man        0.158639\n",
      "galleon    0.146527\n",
      "Name: Destiny’s Landfall: A History of Guam, dtype: float64 \n",
      "\n",
      "Top words for 'The Hale'-Ta Series: HeStorian Taotao Tano': HISTORY OF THE CHAMORRO PEOPLE':\n",
      "people     0.307939\n",
      "ancient    0.286671\n",
      "other      0.272133\n",
      "many       0.200519\n",
      "island     0.190970\n",
      "Name: The Hale'-Ta Series: HeStorian Taotao Tano': HISTORY OF THE CHAMORRO PEOPLE, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# METHOD 1 : TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "C = vectorizer.fit_transform(text_list)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# converting countvectorizer to TD-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(C)\n",
    "\n",
    "# convert dataframe\n",
    "titles = [metadata['title'] for metadata in metadata_list]\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=feature_names, index=titles)\n",
    "\n",
    "# display top words per document\n",
    "import numpy as np\n",
    "top_n = 5  # adjust number of top words to show\n",
    "for title in titles:\n",
    "    print(f\"Top words for '{title}':\")\n",
    "    top_words = df_tfidf.loc[title].nlargest(top_n)\n",
    "    print(top_words, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES ON VECTORIZING:**\n",
    "- Vectorizing is the process of converting raw text data into numerical representations (vectors) that machine learning algorithms can understand and process. Since algorithms work with numbers, not words, this step is essential for tasks like text classification, clustering, or analysis.\n",
    "- CountVectorizer (Bag-Of-Words) counts how many times each word appears in a document\n",
    "- TF-IDF reflects term importance (see below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES ON TF-IDF:**\n",
    "- Converting from CountVectorizer to TF-IDF involves transforming raw word counts into a weighted representation that reflects term importance across documents where\n",
    "- CountVectorizer: outputs a term-frequency matrix (e.g. \"The cat sat on the mat\" > {'the':2, 'cat':1, 'sat':1, ...})\n",
    "- TF-IDF adjusts these two counts using Term Frequency (how often a word appears) and Inverse Document Frequency (penalizes terms that may appear in many documents)\n",
    "- Resulting in a boost in rare and meaninful terms and a downweight of common terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjective governing 'guam': past\n",
      "Adjective near 'guam': in\n",
      "Adjective near 'guam': saw\n",
      "Adjective near 'guam': in\n",
      "Adjective near 'guam': neutralize\n",
      "Adjective near 'guam': be\n",
      "Adjective near 'guam': in\n",
      "Adjective near 'guam': confine\n",
      "Adjective near 'guam': in\n",
      "Adjective near 'guam': in\n",
      "Adjective near 'guam': in\n",
      "Adjective near 'guam': from\n",
      "Adjective near 'guam': people\n",
      "Adjective near 'guam': scouted\n",
      "Adjective near 'guam': in\n",
      "Adjective near 'guam': in\n",
      "Adjective near 'guam': settlements\n",
      "Co-occurrences: ['past', 'modern', 'postwar', 'modern', 'strong', 'fortified', 'vulnerable', 'defenseless', 'roadless', 'southern', 'central', 'northern', 'Northern', 'southern', 'northern', 'northern', 'central']\n"
     ]
    }
   ],
   "source": [
    "# METHOD 1 (continued) : Co-occurrences\n",
    "\n",
    "corpus = raw_text_list\n",
    "target_noun = \"guam\"\n",
    "co_occurrences = []\n",
    "\n",
    "for doc in corpus:\n",
    "    spacy_doc = nlp(doc)\n",
    "    for token in spacy_doc:\n",
    "        if token.text.lower() == target_noun:\n",
    "            for child in token.children:\n",
    "                if child.pos_ == \"ADJ\":\n",
    "                    print(f\"Adjective near '{target_noun}': {token.head.text}\")\n",
    "                    co_occurrences.append(child.text)\n",
    "            if token.head.pos_ == \"ADJ\":\n",
    "                print(f\"Adjective governing '{target_noun}': {token.head.text}\")\n",
    "                co_occurrences.append(token.head.text)\n",
    "\n",
    "print(\"Co-occurrences:\", co_occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  sentiment\n",
      "0  A Marianas Mosaic: Signs and Shifts in Contemp...   0.087177\n",
      "1  GUAM: TWO INVASIONS AND THREE MILITARY OCCUPAT...   0.026302\n",
      "2  Legacy of a Political Union: A Founding Father...   0.112685\n",
      "3            Chamoru Legends: A Gathering of Stories   0.097129\n",
      "4              Destiny’s Landfall: A History of Guam   0.038031\n",
      "5  The Hale'-Ta Series: HeStorian Taotao Tano': H...   0.100835\n"
     ]
    }
   ],
   "source": [
    "# METHOD 1 (continued) : Sentiment Analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "# create dataframe\n",
    "df_corpus = pd.DataFrame(metadata_list)  # create dataframe\n",
    "\n",
    "df_corpus[\"sentiment\"] = [TextBlob(text).sentiment.polarity for text in text_list]\n",
    "print(df_corpus[[\"title\", \"sentiment\"]])  # title for context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on Sentiment Analysis:\n",
    "- Sentiment creates a spectrum of sentiment based on negative (-), neutral (0), and positive (+) words throughout the text. In this case, most of the texts are neutral to netural-positive which could tell us something based on the nature / purpose of the texts being written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 0 documents\n"
     ]
    }
   ],
   "source": [
    "print(f\"Extracted {len(texts)} documents\")\n",
    "for i, text in enumerate(texts[:3]):  # print first 3 documents\n",
    "    print(f\"Document {i}: {text[:500]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 6\n",
      "\n",
      "Document 1:\n",
      "\n",
      "\n",
      "Introduction\n",
      "project supported in great measure by a generous grant from the Northern Marianas\n",
      "                    Humanities Council, along with matching funds from the Northern Marianas\n",
      "                    College (NMC). The book is a collection of essays, articles, and narratives that ex-\n",
      "                    plores some of the many topics relevant to contemporary life in the Marianas.\n",
      "As we embarked on this project, we had two primary goals. One was to meaningfully\n",
      "                    contr\n",
      "\n",
      "Document 2:\n",
      "\n",
      "\n",
      "INTRODUCTION START POINT\n",
      "The purpose of the War in the Pacific National Historical Park is “to commemorate the bravery and sacrifice of those participating in the campaigns of the Pacific theater of World War 11... 4 Army, Navy and support personnel of Japan and Korea fought against Army, Navy and support personnel of allied Western nations ~- United States, Great Britain, Netherlands, China, New Zealand and Australia. Scenes of the fighting, occupations and offensive-defensive preparations we\n",
      "\n",
      "Document 3:\n",
      "\n",
      "\n",
      "FOREWARD\n",
      "The author of this memoir describes the critical efforts of the early politicians and community leaders of the former Marianas District located in the Micronesian region and a part of the Trust Territory of the Pacific Islands under the United States in accordance with the mandate of the United Nations Trusteeship Agreement.\n",
      "This memoir describes a critical turning point in the political history of the former Marianas District in Micronesia. Under the mandate of the United Nations Tru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "filepath = \"/Users/ricky/digital_texts/corpus/files/0_tei_files/finalized_tei\"\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "# iterate over all files\n",
    "for file in os.scandir(filepath):\n",
    "    if file.name.startswith('.') or not file.is_file():  # skip hidden\n",
    "        continue\n",
    "\n",
    "    label = \"tei_text\"  \n",
    "\n",
    "    try:\n",
    "        with open(file.path, encoding=\"utf8\") as input_file:\n",
    "            xml_content = input_file.read()\n",
    "        soup = bs(xml_content, \"xml\")\n",
    "        text = soup.body.get_text() if soup.body else soup.get_text()  \n",
    "\n",
    "        if text.strip():  # make sure not empty\n",
    "            texts.append(text)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Skipping empty document: {file.path}\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(f'Skipping non-text file: {file.path}')\n",
    "\n",
    "# debug: print collected texts\n",
    "print(\"Number of documents:\", len(texts))\n",
    "for i, text in enumerate(texts[:3]):  # first 3 texts\n",
    "    print(f\"\\nDocument {i + 1}:\\n{text[:500]}\")  # first 500 characters\n",
    "\n",
    "# vectorize\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, min_df=2, stop_words=\"english\")  \n",
    "vectorized_texts = vectorizer.fit_transform(texts)\n",
    "\n",
    "# train classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(vectorized_texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store -> File\n",
      "marianas_mosiac.xml -> File\n",
      "guam_two_invasions_and_three_military_occupations.xml -> File\n",
      "legacy_of_a_political_union.xml -> File\n",
      "eng_chamoru_legends.xml -> File\n",
      "destinys_landfall.xml -> File\n",
      "history_of_the_chamorro_people.xml -> File\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# for entry in os.scandir(filepath):\n",
    "    # print(entry.name, \"->\", \"Folder\" if entry.is_dir() else \"File\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts: 6\n",
      "Number of labels: 0\n",
      "Labels: []\n"
     ]
    }
   ],
   "source": [
    "# print(\"Number of texts:\", len(texts))\n",
    "# print(\"Number of labels:\", len(labels))\n",
    "# print(\"Labels:\", labels)  # Should contain meaningful values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous model and vectorizer deleted. Resetting...\n",
      "Done extracting text from files.\n",
      "Vectorizing texts... Done.\n",
      "Building LDA model using training set... Done.\n",
      "Top words per topic:\n",
      "Topic 1: guamanians, japan, naval, navy, army, pp, guns, lvt, landing, invasion\n",
      "Topic 2: ancient, vitores, spaniards, maga, missionaries, society, lahi, padre, ancestors, think\n",
      "Topic 3: ko, hilitai, elena, nåna, sirena, carabao, cow, skin, fruit, maybe\n",
      "Topic 4: chamoru, generation, cnmi, halo, filipino, chamorus, healers, refaluwasch, 2017, art\n",
      "\n",
      " Model and vectorizer saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from joblib import dump\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import gc  # Import garbage collector\n",
    "\n",
    "# Reset Model and Vectorizer\n",
    "# if 'lda' in locals():\n",
    "    # del lda  # Delete LDA model\n",
    "# if 'vectorizer' in locals():\n",
    "    # del vectorizer  # Delete vectorizer\n",
    "\n",
    "gc.collect()  # force garbage collection\n",
    "\n",
    "print(\"Previous model and vectorizer deleted. Resetting...\")\n",
    "\n",
    "# load tei files\n",
    "folder_path = \"/Users/ricky/digital_texts/corpus/files/0_tei_files/finalized_tei\"\n",
    "\n",
    "texts = []\n",
    "filenames = []\n",
    "\n",
    "for file in os.scandir(folder_path):\n",
    "    if file.name.startswith('.') or not file.is_file():\n",
    "        continue  # Skip hidden files or directories\n",
    "    \n",
    "    try:\n",
    "        with open(file.path, encoding=\"utf8\") as f:\n",
    "            xml_content = f.read()\n",
    "        \n",
    "        # Parse XML and extract <body> text\n",
    "        soup = bs(xml_content, \"xml\")\n",
    "        text = soup.body.get_text() if soup.body else soup.get_text()\n",
    "        \n",
    "        if text.strip():  # Only keep non-empty text\n",
    "            texts.append(text)\n",
    "            filenames.append(file.name)\n",
    "        else:\n",
    "            print(f\"Skipping empty document: {file.path}\")\n",
    "    \n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Skipping unreadable file: {file.path}\")\n",
    "\n",
    "# convert to dataframe\n",
    "df = pd.DataFrame({\"filename\": filenames, \"text\": texts})\n",
    "print(\"Done extracting text from files.\")\n",
    "\n",
    "\n",
    "# vectorize\n",
    "print(\"Vectorizing texts...\", end=\" \", flush=True)\n",
    "vectorizer = CountVectorizer(min_df=0.01, max_df=0.6, stop_words=\"english\")\n",
    "vectorized_data = vectorizer.fit_transform(df.text)\n",
    "print(\"Done.\")\n",
    "\n",
    "# train lda model\n",
    "print(\"Building LDA model using training set...\", end=\" \", flush=True)\n",
    "n_topics = 4 # adjust as needed\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, learning_decay=0.8, random_state=1)\n",
    "doc_topic_distrib = lda.fit_transform(vectorized_data)\n",
    "print(\"Done.\")\n",
    "\n",
    "# display topics\n",
    "print(\"Top words per topic:\")\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "    print(f\"Topic {topic_idx + 1}: {', '.join(top_words)}\")\n",
    "\n",
    "# assign topics to documents\n",
    "df[\"topic\"] = doc_topic_distrib.argmax(axis=1)\n",
    "\n",
    "# save model & vector\n",
    "dump(lda, \"lda_model.joblib\")\n",
    "dump(vectorizer, \"vectorizer.joblib\")\n",
    "\n",
    "print(\"\\n Model and vectorizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(vectorizer, \"tf_vectorizer.joblib\")\n",
    "dump(nmf, \"nmf_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES ON TOPIC MODELING:**<br><br>\n",
    "When to INCREASE n_topics (e.g., from 6 to 8 or 10):\n",
    "- If topics seem too broad or contain mixed themes in one topic.\n",
    "- If words from different subjects are appearing together in a single topic.\n",
    "- If you suspect there are more distinct themes in your documents.<br><br>\n",
    "When to DECREASE n_topics (e.g., from 6 to 4 or 5):\n",
    "- If topics seem too fragmented, with very specific themes that might not be useful.\n",
    "- If some topics repeat similar themes with slight variations.\n",
    "- If you get many topics that don’t seem meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    A Marianas Mosaic: Signs and Shifts in Contemporary Island Life  \\\n",
      "A Marianas Mosaic: Signs and Shifts in Contempo...                                           1.000000                 \n",
      "GUAM: TWO INVASIONS AND THREE MILITARY OCCUPATIONS                                           0.417471                 \n",
      "\n",
      "                                                    GUAM: TWO INVASIONS AND THREE MILITARY OCCUPATIONS  \n",
      "A Marianas Mosaic: Signs and Shifts in Contempo...                                           0.417471   \n",
      "GUAM: TWO INVASIONS AND THREE MILITARY OCCUPATIONS                                           1.000000   \n"
     ]
    }
   ],
   "source": [
    "# COSINE SIMILARITY\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(X)\n",
    "df_similarity = pd.DataFrame(cosine_sim, index=titles, columns=titles)\n",
    "\n",
    "# Show similarity between first two texts\n",
    "print(df_similarity.iloc[:2, :2])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digital_texts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
